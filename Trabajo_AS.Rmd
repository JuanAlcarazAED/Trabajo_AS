---
title: "Compresión de imágenes y vídeos usando wavelets"
subtitle: "Análisis de Señales. Máster en Ciencia de Datos - UV"
author: "Adrián Carrasco, Clara Montalvá, Javier Herrero, Fabián Calvo y Juan Alcaraz"
date: "Curso 2025-2026"
output:
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
  html_document:
    echo: true
    number_sections: true
    theme: lumen
    toc: true
  bookdown::html_document2:
    echo: true
    number_sections: true
    theme: spacelab
    toc: true
    figure_caption: "Figura"
    table_caption: "Tabla"
  html_notebook:
    echo: true
    number_sections: true
    toc: true
  bookdown::pdf_document2:
    toc: true
    toc_depth: 3
    number_sections: true
    figure_caption: "Figura" # Referencias en castellano
    table_caption: "Tabla"
always_allow_html: true
params:
  lang: spanish
lang: "`r switch(params$lang, ES = 'es-ES', EN = 'en-US')`"
language:
  label:
    fig: 'Figura '
    tab: 'Tabla '
    eq: 'Ecuación '
    thm: 'Teorema '
    lem: 'Lema '
    def: 'Definición '
    cor: 'Corolario '
    prp: 'Proposición '
    exm: 'Ejemplo '
    exr: 'Ejercicio '
    proof: 'Demostración. '
    remark: 'Nota: '
    solution: 'Solución. '
bibliography: referencias.bib
csl: ieee.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)

if (!require("pacman")) install.packages("pacman")

pacman::p_load(imager,  gsignal, wavethresh, magick, av, wavelets, tuneR, RColorBrewer, waveslim)
```

# Introducción

La capacidad de almacenar y compartir archivos multimedia de forma eficiente es hoy una necesidad fundamental. Debido al gran tamaño de las imágenes y vídeos actuales, es imprescindible utilizar técnicas de compresión que reduzcan el peso de los archivos sin que la pérdida de calidad sea demasiado evidente para el usuario.

Históricamente, el método más utilizado ha sido la Transformada Coseno Discreta (DCT), que es la base del formato JPEG. Aunque este método es eficaz, suele generar distorsiones visuales cuando se busca una compresión muy alta. Como alternativa, surgió la Transformada Wavelet Discreta (DWT), que analiza la información en diferentes niveles de detalle y permite una reconstrucción más limpia. 

# Revisión bibliográfica

# Objetivos

Este proyecto tiene como objetivo evaluar y comparar la eficacia de los algoritmos de compresión IDWT, DCT y SPIHT aplicados a un conjunto de datos. Para ello, se han seleccionado cuatro imágenes con diferentes propiedades. Esta selección permite observar cómo cada algoritmo gestiona conceptos como la entropía, la retención de nitidez y el ruido.

También se pretende aplicar este objetivo de compresión al vídeo y audio. En el caso del audio, se explora el dominio wavelet mediante el mejor valor umbral de energía, analizando la redundancia de la señal a través de la entropía de Shannon. Este enfoque busca no solo aplicar las fórmulas matemáticas, sino comprender la relación entre la concentración de energía de una señal y su capacidad para ser comprimida.

A través del análisis de métricas de error como el MSE (Mean Squared Error) y el PSNR (Peak Signal-to-Noise Ratio), se pretende demostrar por qué las wavelets se han convertido en la base de estándares actuales como el JPEG 2000. El análisis final se centra en determinar qué método ofrece el equilibrio óptimo entre la reducción del peso del archivo y la mayor reconstrucción visual posible de la imagen.

# Descripción de los datos

Para evaluar la eficacia de los algoritmos de compresión, hemos seleccionado un conjunto de cuatro imágenes realizadas por nosotros mismos con características visuales distintas para observar cómo responden los métodos ante diferentes niveles de entropía, detalle y origen de los datos.

La primera fotografía escogida es de un acantilado, que al ser dominada por el azul del mar y el cielo, cuenta con grandes zonas de color uniforme. Esto nos permite evaluar la eficiencia de la compresión en imágenes con "poca información" aparente o redundancia, donde los algoritmos deberían optimizar mejor el peso del archivo.

La segunda imagen contiene una gran variedad de colores y tonos a lo largo de toda la imagen, ya que se trata de una fotografía a distintas flores. Al contrario que la anterior, esta imagen sirve para probar cómo los algoritmos gestionan la retención del color y la nitidez en zonas con mucha información visual y cambios de color constantes.

La tercera fotografía se trata de una imagen nocturna de una avenida, utilizada para analizar qué ocurre en condiciones de poca luz. En estas imágenes suele aparecer ruido digital y sombras, lo que supone un reto donde la pérdida de información suele ser más evidente tras aplicar los procesos de compresión.

Por último, se escogió una imagen generada mediante Inteligencia Artificial recreando a los cinco miembros del grupo al estilo de Estudio Ghibli. Al no estar capturada por una cámara real, sino generada digitalmente, posee bordes definidos y colores planos que nos sirven para comparar cómo se comporta la compresión en creación digital.


```{r}
ruta_acantilado<-"im_2/acantilado.jpg"
ruta_flores<-"im_2/flores.jpg"
ruta_noche<-"im_2/noche.jpg"
ruta_dibujo<-"im_2/dibujo.PNG"

acantilado<-load.image(ruta_acantilado)
flores<-load.image(ruta_flores)
noche<-load.image(ruta_noche)
dibujo<-load.image(ruta_dibujo)
```


```{r}
par(mfrow = c(2, 2), mar = c(0.25, 0.25, 0.25, 0.25)) 

plot(acantilado, axes=F)
plot(flores, axes=F)
plot(noche, axes=F)
plot(dibujo, axes=F)
```

Para el estudio de la compresión de vídeo se ha utilizado un úncio vídeo elaborado por nosotros. Al vídeo se le ha añadido música de fondo con el objetivo de enriquecer el contenido de audio. Tiene una duración total de 7 segundos y fue grabado a una tasa de 30 fotogramas por segundo. El archivo de vídeo puede consultarse en el siguiente enlace: https://github.com/JuanAlcarazAED/Trabajo_AS/blob/main/data/video.mp4.


# Metodología


```{r}
source("compresion_IDWT.R")
source("compresion_DCT.R")
source("compresion_DCT_opt.R")
source("metricas.R")
source("funciones_audio.R")
source("Codificacion_SPIHT.R")
source("compresion_SPIHT.R")

```

## Compresión IDWT

```{r}
acantilado_IDWT<-compresion_IDWT(ruta_acantilado)
flores_IDWT<-compresion_IDWT(ruta_flores)
noche_IDWT<-compresion_IDWT(ruta_noche)
dibujo_IDWT<-compresion_IDWT(ruta_dibujo)
```

```{r}
acantilado_IDWT<-comprobacion_dim(acantilado, acantilado_IDWT)
flores_IDWT<-comprobacion_dim(flores, flores_IDWT)
noche_IDWT<-comprobacion_dim(noche, noche_IDWT)
dibujo_IDWT<-comprobacion_dim(dibujo, dibujo_IDWT)
```

```{r}
par(mfrow = c(2, 2), mar = c(0.25, 0.25, 0.25, 0.25)) 

plot(acantilado_IDWT, axes=F)
plot(flores_IDWT, axes=F)
plot(noche_IDWT, axes=F)
plot(dibujo_IDWT, axes=F)
```

## Compresión DCT

```{r}
acantilado_DCT<-compresion_DCT_opt(ruta_acantilado)
flores_DCT<-compresion_DCT_opt(ruta_flores)
noche_DCT<-compresion_DCT_opt(ruta_noche)
dibujo_DCT<-compresion_DCT_opt(ruta_dibujo)
```

```{r}
par(mfrow = c(2, 2), mar = c(0.25, 0.25, 0.25, 0.25)) 

plot(acantilado_DCT, axes=F)
plot(flores_DCT, axes=F)
plot(noche_DCT, axes=F)
plot(dibujo_DCT, axes=F)
```

## Compresión SPIHT

```{r}
obtener_potencia_4 <- function(x) {
  return(4^round(log(x,4)))
}

resize_SPIHT <- function(img){
  nuevo_tamaño <- obtener_potencia_4(max(width(img), height(img)))
  img <- resize(img, size_x = nuevo_tamaño, size_y = nuevo_tamaño)
}
```

```{r}
compresion_SPIHT <- function(imagen, J = 8, wf = "haar", max_bits = NULL, max_iter = 500){
  
  # Redimensionar la imagen y pasarla a escala de grises
  
  imagen_re4<-resize_SPIHT(imagen)
  
  imagen_gray <- grayscale(imagen_re4)
  
  # Transformada wavelet 2D
  
  dwt_obj <- dwt.2d(imagen_gray, wf = wf, J = J)
  # J: niveles de descomposición
  # wf: wavelet
  
  # Ensamblar matriz wavelet completa
  
  W <- Ensamblar(dwt_obj)
  
  # Codificar con SPIHT
  
  bitstream <- SPIHT_Codificar(W, max_bits = max_bits, max_iter = max_iter)
  
  # Tamaño en memoria del bitstream
  
  tamanno_bytes <- object.size(bitstream)
  tamanno_kb <- as.numeric(tamanno_bytes) / 1024
  cat("Tamaño del bitstream:", tamanno_kb, "KB\n")
  
  # Decodificar SPIHT
  
  n_inicial <- floor(log2(max(abs(W))))
  W_rec <- SPIHT_Decodificar(bitstream, size = nrow(W), n_inicial = n_inicial)
  
  # Desensamblar matriz wavelet reconstruida
  
  dwt_rec <- Desensamblar(W_rec)
  
  # Reconstruir imagen con IDWT
  
  attributes(dwt_rec) <- attributes(dwt_obj)
  dwt_rec$LH8 <- as.matrix(dwt_rec$LH8)
  dwt_rec$HL8 <- as.matrix(dwt_rec$HL8)
  dwt_rec$HH8 <- as.matrix(dwt_rec$HH8)
  dwt_rec$LL8 <- as.matrix(dwt_rec$LL8)
  
  img_rec <- idwt.2d(dwt_rec)
  
  save.image(as.cimg(img_rec), file = paste("Reconstruccion_", max_iter, "_iter.jpeg",sep=""))
  
  return(img_rec)
}
```

```{r}
# acantilado_SPIHT<-compresion_SPIHT(acantilado)
```

```{r}
par(mfrow = c(1,2), mar = c(2,2,2,2))
plot(as.cimg(img_mat), main = "Original")
plot(as.cimg(img_rec), main = "Reconstruida SPIHT")
par(mfrow = c(1,1))
```

```{r}
PSNR <- function(orig, rec) {
  mse <- mean((orig - rec)^2)
  10 * log10(1 / mse)
}

orig_n <- (img_mat - min(img_mat)) / (max(img_mat) - min(img_mat))
rec_n  <- (img_rec - min(img_rec)) / (max(img_rec) - min(img_rec))

psnr_val <- PSNR(orig_n, rec_n)
cat("PSNR aproximado:", psnr_val, "dB\n")
```


## Compresión de vídeo

### Compresión de imagen

### Compresión de audio

La compresión del audio se va a realizar en el dominio wavelet mediante el umbralado selectivo de la energía de los coeficientes. El planteamiento se centra en estudiar la redundancia de la señal, utilizando la entropía de Shannon calculada a partir de la distribución de energías de la señal umbralizada [@mallat2009]. Se busca un equilibrio entre maximizar la redundancia y la compresión del archivo sin perder información relevante.

La compresión se realiza mediante un umbralado global basado en la energía acumulada. Primero se ordenan todos los coeficientes wavelet de mayor a menor energía para identificar su peso en la señal. Posteriormente se define un porcentaje de preservación energética determinado por un valor umbral $\lambda$ y se establecen a cero todos aquellos coeficientes cuya contribución queda por debajo del valor umbral.

La frecuencia de muestreo del audio es de 44100 Hz, dado que cada nivel de descomposición divide el espectro a la mitad, elegir 6 niveles es razonable ya que se llega a cubrir las frecuencias medias y bajas donde se concentra energías. 

```{r}
audio <- readWave("data/audio.wav")
n.levels <- 6
```

El audio a estudiar está en estéreo, la amplitud del audio para ambos canales se puede observar en la siguiente figura.

```{r,dev="png", dpi=300, fig.width=10, fig.height=4}

N <- length(audio@left)
freq <- audio@samp.rate
tiempo <- (0:(N-1)) / freq


par(mfrow = c(1, 2), mar = c(4, 4, 2, 1)) 


plot(tiempo, audio@left, type = "l",
     main = "Canal Izquierdo",
     xlab = "Tiempo (segundos)", ylab = "Amplitud")


plot(tiempo, audio@right, type = "l",
     main = "Canal Derecho",
     xlab = "Tiempo (segundos)", ylab = "")

par(mfrow = c(1, 1))
```

El parámetro fundamental en este estudio es la energía, definida como la amplitud al cuadrado de la señal. En la siguiente figura se representa la energía de la señal, donde se observa que ambos canales presentan picos pronunciados. Esta concentración de energía indica una baja entropía, mientras que una distribución de energía uniforme dificultaría la compresión. Una señal con picos de energía concentrado permite un umbralado más eficiente en el dominio wavelet.


La compresión de una señal mediante umbralizado de energía en el dominio wavelet busca concentrar la energía de la señal en un número reducido de coeficientes, eliminando aquellos que aportan poca contribución energética. Este proceso modifica la distribución estadística de la energía, haciendo que esta se concentre en menos estados. Como consecuencia la señal resultante presenta una distribución menos uniforme, lo que conlleva a una reducción de la entropía.

Para analizar de forma cuantitativa este efecto, se estudia la entropía de Shannon asociada a la distribución de energía de los coeficientes wavelet tras haber umbralizado. La entropía se calcula a partir del histograma de energías, en el que cada bin representa un simbolo discreto. De esta forma se puede medir de manera robusta el grado de concentración energética dado por el parámetro umbral $\lambda$. Con el fin de normalizar la magnitud se introduce el concepto de redundancia definida como:

$$R(\lambda)=1-\frac{H(\lambda)}{H_{max}}$$

Donde $H(\lambda)$ es la entropía de la distribución de energía de los coeficientes wavelet tras umbralizar y $H_{max}=\log_2(N_{bins})$ con $N_{bins}$ el número de bins que se mantiene constante para todos los valores de $\lambda$. Una redundancia elevada indica que la entropía de la señal está concentrada en un número reducido de estados, lo que indica que la señal presenta una alta compresibilidad. 

Se ha seleccionado el formato `.rds` para el análisis del almacenamiento debido a su capacidad para preservar la estructura de los coeficientes wavelet, incluyendo los valores nulos generados por el umbralado. A diferencia del formato `.wav`, que almacena la señal reconstruida en el dominio temporal sin tener en cuenta la presencia de ceros. 
El porcentaje de archivo comprimido se calcula como el tamaño relativo del archivo `.rds` normalizado respecto al tamaño máximo obtenido para $\lambda=0$, correspondiene al caso sin compresión. De esta manera, esta magnitud refleja la reducción de información estructural debida al umbralado.


# Resultados

```{r}
MSE(acantilado, acantilado_IDWT)
MSE(acantilado, acantilado_DCT)
```

```{r}
MSE(flores, flores_IDWT)
MSE(flores, flores_DCT)
```

```{r}
MSE(noche, noche_IDWT)
MSE(noche, noche_DCT)
```

```{r}
MSE(dibujo, dibujo_IDWT)
MSE(dibujo, dibujo_DCT)
```

```{r}
PSNR(acantilado, acantilado_IDWT)
PSNR(acantilado, acantilado_DCT)
```

```{r}
PSNR(flores, flores_IDWT)
PSNR(flores, flores_DCT)
```

```{r}
PSNR(noche, noche_IDWT)
PSNR(noche, noche_DCT)
```

```{r}
PSNR(dibujo, dibujo_IDWT)
PSNR(dibujo, dibujo_DCT)
```

```{r}
CR(ruta_acantilado, "data_comp/acantilado_IDWT.jpg")
CR(ruta_acantilado, "data_comp/acantilado_DCT.jpg")
```

```{r}
CR(ruta_flores, "data_comp/flores_IDWT.jpg")
CR(ruta_flores, "data_comp/flores_DCT.jpg")
```

```{r}
CR(ruta_noche, "data_comp/noche_IDWT.jpg")
CR(ruta_noche, "data_comp/noche_DCT.jpg")
```

```{r}
CR(ruta_dibujo, "data_comp/dibujo_IDWT.jpg")
CR(ruta_dibujo, "data_comp/dibujo_DCT.jpg")
```

## Compresión de vídeo

### Compresión imagen

### Compresión del audio

Para buscar el mejor valor umbral se va a buscar aquel valor que tiene una alta reducción del archivo maximizando el valor de la redundancia sin eliminar información relevante. En la siguiente figura se representa el porcentaje de archivo comprimido frente a la redundancia de la señal wavelet.

```{r,fig.width=6, fig.height=4}
lambda_vals <- seq(0, 1, by = 0.1)
lambda_vals_2<-seq(0, 0.3, by = 0.1)
red_data <- redundancy_vs_lambda(
  audio,
  n.levels,
  lambda_vals = lambda_vals
)

size_data <- size_vs_lambda(
  audio     = audio,
  n.levels  = n.levels,
  lambda_vals = lambda_vals
)

plot(
  red_data$redundancy,
  size_data$size_bytes/max(size_data$size_bytes),
  type = "b", pch = 19,
  col = "darkred",
  xlab = "Redundancia",
  ylab = "Porcentaje de archivo comprimido",
  main = "Porcentaje de archivo comprimido vs redundancia"
)
text(
  red_data$redundancy[1:3],
  (size_data$size_bytes / max(size_data$size_bytes))[1:3],
  labels = paste0(expression(lambda =), lambda_vals[1:3]),
  pos = 4,
  cex = 0.75
)
grid()

```

Se observa que el valor óptimo, que logra un equilibrio entre una alta redundancia y la preservación de la información de la señal, corresponde a un umbral de $\lambda=0.1$. Por tanto, este será el valor utilizado para la compresión definitiva del audio.


```{r}
# Parámetros
lambda <- 0.1

# DWT + threshold
vals <- dwt_values(audio, n.levels, lambda)

q_left  <- vals$thr_left
q_right <- vals$thr_right

# Codificación
enc_left  <- encode_wt(q_left)
enc_right <- encode_wt(q_right)

# Guardar archivo comprimido
size_bytes <- save_compressed(
  "data_comp/audio_wavelet_comp.rds",
  left  = enc_left,
  right = enc_right,
  filter = "la8",
  n.levels = n.levels
)

#cat("Tamaño del archivo comprimido:", size_bytes/1024, "KB\n")

```

El mapa de calor de los coeficientes de detalle permite visualizar la distribución de la energía de la señal a través de las seis escalas wavelet. Las áreas en rojo representan coeficientes con valores cercanos a cero, mientras que las zonas amarillas y blancas indican la presencia de componentes de alta energía. Tras aplicar el umbral se observa una escasez estructural, especialmente en los niveles más finos $d_1$ y $d_2$. En la siguiente figura se ha representado únicamente el canal izquierdo por simplicidad, pero sería análogo con el canal derecho.

```{r,dev="png", dpi=300, fig.width=10, fig.height=4}
par(mfrow = c(1, 2))
plot_heatmap_wavelet_coef(audio,n.levels,lambda,threshold=F)
plot_heatmap_wavelet_coef(audio,n.levels,lambda,threshold=T)
par(mfrow = c(1, 1))
```

Se ha aplicado una función de expansión para compensar el submuestreo intrínseco de la DWT, donde los niveles más profundos como $d_6$ contienen menos coeficientes que los niveles finos. Permite alinear todas las escalas con la longitud original de la señal, facilitando una comparación visual directa de la energía en cada instante de tiempo.

```{r,fig.width=6, fig.height=4}
plot_energy_vs_coeff(audio,n.levels,lambda)
```

En la representación de la energía capturada frente a coeficientes se observa que una fracción mínima de los coeficientes logra capturar el $90\%$ de la energía total del audio, en torno a los 25000 primeros coeficientes. Esto permite eliminar la gran mayoría de los coeficientes con menor energía sin generar una pérdida de información significativa.



```{r}

wt_left_rec <- decode_wt(enc_left, vals$thr_left)

wt_right_rec <- decode_wt(enc_right, vals$thr_right)

# Señal final
signal_left_rec  <- wavelets::idwt(wt_left_rec)
signal_right_rec <- wavelets::idwt(wt_right_rec)

audio_wav <- Wave(
    left = signal_left_rec,
    right = signal_right_rec,
    samp.rate = audio@samp.rate,
    bit = audio@bit
)
writeWave(audio_wav, "data_comp/audio2comp.wav")


mse_left  <- sqrt(mean((audio@left - signal_left_rec)^2)) /sqrt(mean(audio@left^2))
mse_right <- sqrt(mean((audio@right - signal_right_rec)^2))/sqrt(mean(audio@right^2))


```

Para ver el efecto de la señal comprimida se va a comprar la amplitud de la señal original (rojo) y la señal comprimida (negro). A pesar de haber eliminado solo un $10\%$ de la energía hay un efecto importante en la señal como se puede ver en la figura.

```{r,dev="png", dpi=300, fig.width=10, fig.height=4}
audio_comp <- readWave("data_comp/audio2comp.wav")


N <- length(audio_comp@left)
freq <- audio_comp@samp.rate

tiempo <- (0:(N-1)) / freq


par(mfrow = c(1, 2), mar = c(4, 4, 2, 1)) 


plot(tiempo,audio@left,type="l",col="red",main = "Canal Izquierdo",xlab = "Tiempo (segundos)", ylab = "Amplitud")
lines(tiempo, audio_comp@left, type = "l", col = "black")


plot(tiempo,audio@right,type="l",col="red",main = "Canal Derecho",xlab = "Tiempo (segundos)", ylab = "")
lines(tiempo, audio_comp@right, type = "l", col = "black")

par(mfrow = c(1, 1))
```

Para el valor de $\lambda=0.1$ el error cuadrático medio normalizado tras comprimir en el canal izquierdo es `r round(mse_left,2)` y para el canal derecho `r round(mse_right, 2)`. Esto indica una pérdida apreciable pero concentrada en coeficientes de baja energía, manteniendo una estructura perceptualmente reconocible de la señal.


# Conclusiones

# Link del repositorio


# Referencias
https://github.com/JuanAlcarazAED/Trabajo_AS.git
