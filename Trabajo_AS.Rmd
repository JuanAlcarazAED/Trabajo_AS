---
title: "Compresión de imágenes y vídeos usando wavelets"
subtitle: "Análisis de Señales. Máster en Ciencia de Datos - UV"
author: "Juan Alcaraz, Adrián Carrasco, Fabián Calvo, Javier Herrero, Clara Montalvá"
date: "Curso 2025-2026"
output:
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
  html_document:
    echo: true
    number_sections: true
    theme: lumen
    toc: true
  bookdown::html_document2:
    echo: true
    number_sections: true
    theme: spacelab
    toc: true
    figure_caption: "Figura"
    table_caption: "Tabla"
  html_notebook:
    echo: true
    number_sections: true
    toc: true
  bookdown::pdf_document2:
    toc: true
    toc_depth: 3
    number_sections: true
    figure_caption: "Figura" # Referencias en castellano
    table_caption: "Tabla"
always_allow_html: true
params:
  lang: spanish
lang: "`r switch(params$lang, ES = 'es-ES', EN = 'en-US')`"
language:
  label:
    fig: 'Figura '
    tab: 'Tabla '
    eq: 'Ecuación '
    thm: 'Teorema '
    lem: 'Lema '
    def: 'Definición '
    cor: 'Corolario '
    prp: 'Proposición '
    exm: 'Ejemplo '
    exr: 'Ejercicio '
    proof: 'Demostración. '
    remark: 'Nota: '
    solution: 'Solución. '
bibliography: referencias.bib
csl: ieee.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)

if (!require("pacman")) install.packages("pacman")

pacman::p_load(imager,  gsignal, wavethresh, magick, av, wavelets, tuneR, RColorBrewer, waveslim, tictoc)
```

# Introducción

En la era de la información en la que vivimos, la capacidad de almacenar y compartir archivos multimedia de forma eficiente es una necesidad fundamental. Debido al gran tamaño de las imágenes y vídeos actuales, es imprescindible utilizar técnicas de compresión que reduzcan el peso de los archivos sin que la pérdida de calidad sea demasiado evidente para el usuario.

Históricamente, el método de compresión más utilizado ha sido el de la Transformada de Coseno Discreta (DCT), que es la base del formato JPEG. Aunque este método es eficaz, suele generar distorsiones visuales cuando se busca una compresión muy alta. Como alternativa, surgió la Transformada de Wavelet Discreta (DWT), que analiza la información en diferentes niveles de detalle y permite una reconstrucción más limpia.

# Revisión bibliográfica

# Objetivos

El objetivo de este proyecto es evaluar y comparar la eficacia de los algoritmos de compresión DWT (Discrete Wavelet Transform), DCT (Discrete Cosine Transform) y SPIHT (Set Partitioning in Hierarchical Trees) aplicados a imágenes y a vídeos.

Para las imágenes, seleccionaremos cuatro imágenes con características diversas. Esta selección nos permitirá observar cómo cada algoritmo gestiona conceptos como la entropía, la retención de nitidez y el ruido.

Para la aplicación a la compresión de vídeos, necesitaremos comprimir también el audio. Para ello, exploraremos el dominio wavelet mediante el mejor valor umbral de energía, analizando la redundancia de la señal a través de la entropía de Shannon. Esto nos permitirá comprender la relación entre la concentración de energía de una señal y su capacidad para ser comprimida.

Para la evaluación de los diferentes algoritmos haremos un análisis de métricas de error como el MSE (Mean Squared Error) y el PSNR (Peak Signal-to-Noise Ratio), el SSIM (Structural similarity index measure) o el CR (Compression Rate). Trataremos de determinar qué método ofrece el mayor  equilibrio entre la reducción del peso de la imagen y la mejor reconstrucción visual posible de la misma, buscando entender el motivo por el que las wavelets se han convertido en la base de estándares actuales como el JPEG 2000.

# Descripción de los datos

Para evaluar la eficacia de los algoritmos de compresión, hemos seleccionado un conjunto de cuatro imágenes propias con características visuales y tamaños distintos, lo que nos permitirá observar cómo responden los diferentes métodos de compresión y sus parámetros ante diferentes niveles de entropía, detalle y dimensiones de los datos.

La primera fotografía escogida es de un acantilado, que al ser dominada por el azul del mar y el cielo, cuenta con grandes zonas de color uniforme. Esto nos permite evaluar la eficiencia de la compresión en imágenes con "poca información" aparente o redundancia, donde los algoritmos deberían optimizar mejor el peso del archivo.

La segunda imagen contiene una gran variedad de colores y tonos a lo largo de toda la imagen, ya que se trata de una fotografía a distintas flores. Al contrario que la anterior, esta imagen sirve para probar cómo los algoritmos gestionan la retención del color y la nitidez en zonas con mucha información visual y cambios de color constantes.

La tercera fotografía se trata de una imagen nocturna de una avenida, utilizada para analizar qué ocurre en condiciones de poca luz. En estas imágenes suele aparecer ruido digital y sombras, lo que supone un reto donde la pérdida de información suele ser más evidente tras aplicar los procesos de compresión.

Por último, se escogió una imagen generada mediante Inteligencia Artificial recreando a los cinco miembros del grupo al estilo de Estudio Ghibli. Al no estar capturada por una cámara real, sino generada digitalmente, posee bordes definidos y colores planos que nos sirven para comparar cómo se comporta la compresión en creación digital.


```{r}
# Cargamos inicialmente todas las imágenes y las guardamos desde R, para que las
# métricas basadas en el tamaño de los archivos sean consistentes
ruta_acantilado<-"im_2/acantilado.jpg"
ruta_flores<-"im_2/flores.jpg"
ruta_noche<-"im_2/noche.jpg"
ruta_dibujo<-"im_2/dibujo.png"

acantilado<-load.image(ruta_acantilado)
flores<-load.image(ruta_flores)
noche<-load.image(ruta_noche)
dibujo<-load.image(ruta_dibujo)

save.image(acantilado, ruta_acantilado, quality = 1)
save.image(flores, ruta_flores, quality = 1)
save.image(noche, ruta_noche, quality = 1)
save.image(dibujo, ruta_dibujo, quality = 1)
```

```{r}
# Volvemos a cargar las imágenes
acantilado<-load.image(ruta_acantilado)
flores<-load.image(ruta_flores)
noche<-load.image(ruta_noche)
dibujo<-load.image(ruta_dibujo)
```


```{r}
par(mfrow = c(2, 2), mar = c(0.25, 0.25, 0.25, 0.25)) 

plot(acantilado, axes=F)
plot(flores, axes=F)
plot(noche, axes=F)
plot(dibujo, axes=F)
```

Para el estudio de la compresión de vídeo se ha utilizado un úncio vídeo elaborado por nosotros. Al vídeo se le ha añadido música de fondo con el objetivo de enriquecer el contenido de audio. Tiene una duración total de 7 segundos y fue grabado a una tasa de 30 fotogramas por segundo. El archivo de vídeo puede consultarse en el siguiente enlace: https://github.com/JuanAlcarazAED/Trabajo_AS/blob/main/data/video.mp4.


# Metodología


```{r}
source("compresion_IDWT.R")
source("compresion_DCT.R")
source("compresion_DCT_opt.R")
source("metricas.R")
source("funciones_audio.R")
source("Codificacion_SPIHT.R")
source("compresion_SPIHT.R")
```

## Compresión IDWT

La IDWT (Inverse Discrete Wavelet Transform) es el proceso matemático y algorítmico utilizado para recuperar la señal original x[n] a partir de sus coeficientes wavelet (coeficientes de aproximación y detalle) previamente calculados mediante la DWT. 
Mientras que la DWT descompone la señal en diferentes niveles de resolución, la IDWT realiza el camino inverso, reconstruye la señal sumando las contribuciones de las distintas escalas.

El proceso de reconstrucción se basa en iteraciones que invierten el Algoritmo de Mallat:

1. Proceso Iterativo: La reconstrucción comienza desde el nivel más bajo de resolución, que corresponde a las frecuencias más bajas y avanza nivel por nivel hacia arriba.

2. Combinación de Coeficientes: En cada nivel, la señal se reconstruye combinando los coeficientes de aproximación y los coeficientes de detalle del nivel siguiente.

3. Filtrado y Desplazamiento: Matemáticamente, esto implica aplicar filtros de reconstrucción y operaciones de desplazamiento sobre los coeficientes. 

En imágenes, la IDWT combina los coeficientes verticales, horizontales y diagonales procesados para recuperar la imagen visualizable. Si se han alterado los coeficientes (por ejemplo, para comprimir), la imagen reconstruida tendrá diferencias respecto a la original.

```{r}
acantilado_IDWT<-compresion_IDWT(ruta_acantilado)
flores_IDWT<-compresion_IDWT(ruta_flores)
noche_IDWT<-compresion_IDWT(ruta_noche)
dibujo_IDWT<-compresion_IDWT(ruta_dibujo)
```

```{r}
par(mfrow = c(2, 2), mar = c(0.25, 0.25, 0.25, 0.25)) 

plot(acantilado_IDWT, axes=F)
plot(flores_IDWT, axes=F)
plot(noche_IDWT, axes=F)
plot(dibujo_IDWT, axes=F)
```

## Compresión DCT

La DCT es una operación matemática relacionada con la Transformada de Fourier, pero trabaja solo con números reales (cosenos). Su función principal no es comprimir por sí misma, sino traducir la información de la imagen. Pasa de píxeles de colores (dominio espacial) a frecuencias (dominio de la frecuencia).

Esto se realiza porque el ojo humano es muy sensible a las frecuencias bajas (cambios suaves de color) pero muy poco sensible a las frecuencias altas (detalles finos o ruido). Al separar estas frecuencias, podemos eliminar las que el ojo no ve bien sin que se note demasiado.

Con este método la imagen se divide en bloques de 8x8 píxeles. Al aplicar la fórmula matemática a cada bloque, se obtiene una matriz de frecuencias donde:

  •	Esquina superior izquierda (Componente DC): Contiene la información más importante (el color promedio del bloque).
  
  •	Esquina inferior derecha (Componentes AC): Contienen las frecuencias altas (detalles finos). Aquí es donde se acumulan valores pequeños o prescindibles.
  
Dicha matriz de frecuencias se divide por una "Matriz de Cuantización" predefinida (Q).

  •	El objetivo es que los valores de las frecuencias altas (los detalles que el ojo casi no ve) se conviertan en ceros o números muy bajos al dividirse por números grandes.
  
  •	Es el único paso donde realmente se pierde información irrecuperable.
  
  •	La "Calidad" del JPG (ej. 50% vs 80%) depende de qué tan agresiva sea esta matriz.

Finalmente, se aplica el algoritmo de Huffman. Se asignan códigos binarios muy cortos a los valores que se repiten mucho y códigos más largos a los poco frecuentes. Esto comprime aún más el archivo final sin perder datos adicionales.

```{r}
acantilado_DCT<-compresion_DCT_opt(ruta_acantilado)
flores_DCT<-compresion_DCT_opt(ruta_flores)
noche_DCT<-compresion_DCT_opt(ruta_noche)
dibujo_DCT<-compresion_DCT_opt(ruta_dibujo)
```

```{r}
par(mfrow = c(2, 2), mar = c(0.25, 0.25, 0.25, 0.25)) 

plot(acantilado_DCT, axes=F)
plot(flores_DCT, axes=F)
plot(noche_DCT, axes=F)
plot(dibujo_DCT, axes=F)
```

## Compresión SPIHT

```{r}
obtener_potencia_4 <- function(x) {
  return(4^round(log(x,4)))
}

resize_SPIHT <- function(img){
  nuevo_tamaño <- obtener_potencia_4(max(width(img), height(img)))
  img <- resize(img, size_x = nuevo_tamaño, size_y = nuevo_tamaño)
}
```

```{r, comment = TRUE}
compresion_SPIHT <- function(ruta_imagen, ruta_imagen_comp = "data_comp", J = 8, wf = "haar", max_bits = NULL, max_iter = 100){
  
  # Cargar la imagen, redimensionarla y separarla en canales
  
  img <- load.image(ruta_imagen)
  
  ancho <- width(img)
  alto <- height(img)
  
  img_re4 <- resize_SPIHT(img)
  
  canales <- imsplit(img_re4, "c")
  
  procesar_canal <- function(canal) {
    # matriz <- as.matrix(canal)
    
    # Transformada wavelet 2D
  
    dwt_obj <- dwt.2d(canal, wf = wf, J = J)
    # J: niveles de descomposición
    # wf: wavelet
    
    # Ensamblar matriz wavelet completa
    
    W <- Ensamblar(dwt_obj)
    
    # Codificar con SPIHT
    
    bitstream <- SPIHT_Codificar(W, max_bits = max_bits, max_iter = max_iter)
    
    # Tamaño en memoria del bitstream
    
    tamanno_bytes <- object.size(bitstream)
    tamanno_kb <- as.numeric(tamanno_bytes) / 1024
    cat("Tamaño del bitstream:", tamanno_kb, "KB\n")
    
    # Decodificar SPIHT
    
    n_inicial <- floor(log2(max(abs(W))))
    W_rec <- SPIHT_Decodificar(bitstream, size = nrow(W), n_inicial = n_inicial)
    
    # Desensamblar matriz wavelet reconstruida
    
    dwt_rec <- Desensamblar(W_rec)
    
    # Reconstruir imagen con IDWT
    
    attributes(dwt_rec) <- attributes(dwt_obj)
    dwt_rec$LH8 <- as.matrix(dwt_rec$LH8)
    dwt_rec$HL8 <- as.matrix(dwt_rec$HL8)
    dwt_rec$HH8 <- as.matrix(dwt_rec$HH8)
    dwt_rec$LL8 <- as.matrix(dwt_rec$LL8)
    
    img_rec <- idwt.2d(dwt_rec)
    
    img_recuperada <- as.cimg(img_rec)
    
    # img_recuperada <- (img_recuperada + abs(img_recuperada)) / 2 
    # img_recuperada <- (img_recuperada - (img_recuperada - 1) * (img_recuperada > 1))
    
    return(img_recuperada)
  }
  
  canales_comprimidos <- lapply(canales, procesar_canal)
  img_final <- imappend(canales_comprimidos, axis = "c")
  
  img_final <- resize(img_final, size_x = ancho, size_y = alto)
  
  nombre_archivo <- tools::file_path_sans_ext(basename(ruta_imagen))
  
  ruta_salida <- file.path(ruta_imagen_comp, paste0(nombre_archivo, "_SPIHT.jpg"))
  
  save.image(img_final, ruta_salida, quality = 1)
  
  return(img_final)
}
```

```{r}
# acantilado_SPIHT<-compresion_SPIHT(acantilado)
```

```{r, comment = TRUE}
# par(mfrow = c(1,2), mar = c(2,2,2,2))
# plot(as.cimg(img_mat), main = "Original")
# plot(as.cimg(img_rec), main = "Reconstruida SPIHT")
# par(mfrow = c(1,1))
```

```{r, comment = TRUE}
# PSNR <- function(orig, rec) {
#   mse <- mean((orig - rec)^2)
#   10 * log10(1 / mse)
# }
# 
# orig_n <- (img_mat - min(img_mat)) / (max(img_mat) - min(img_mat))
# rec_n  <- (img_rec - min(img_rec)) / (max(img_rec) - min(img_rec))
# 
# psnr_val <- PSNR(orig_n, rec_n)
# cat("PSNR aproximado:", psnr_val, "dB\n")
```


## Compresión de vídeo

```{r}
# Separar imagen y audio del vídeo para la compresión separada (funciones_auido.R)
sep_audio_video()

```



### Compresión de imagen

### Compresión de audio

La compresión del audio se va a realizar en el dominio wavelet mediante el umbralado selectivo de la energía de los coeficientes. El planteamiento se centra en estudiar la redundancia de la señal, utilizando la entropía de Shannon calculada a partir de la distribución de energías de la señal umbralizada [@mallat2009]. Se busca un equilibrio entre maximizar la redundancia y la compresión del archivo sin perder información relevante.

La compresión se realiza mediante un umbralado global basado en la energía acumulada. Primero se ordenan todos los coeficientes wavelet de mayor a menor energía para identificar su peso en la señal. Posteriormente se define un porcentaje de preservación energética determinado por un valor umbral $\lambda$ y se establecen a cero todos aquellos coeficientes cuya contribución queda por debajo del valor umbral.

La frecuencia de muestreo del audio es de 44100 Hz, dado que cada nivel de descomposición divide el espectro a la mitad, elegir 6 niveles es razonable ya que se llega a cubrir las frecuencias medias y bajas donde se concentra energías. 

```{r}
audio <- readWave("data/audio.wav")
n.levels <- 6
```

El audio a estudiar está en estéreo, la amplitud del audio para ambos canales se puede observar en la siguiente figura.

```{r,dev="png", dpi=300, fig.width=10, fig.height=4}

N <- length(audio@left)
freq <- audio@samp.rate
tiempo <- (0:(N-1)) / freq


par(mfrow = c(1, 2), mar = c(4, 4, 2, 1)) 


plot(tiempo, audio@left, type = "l",
     main = "Canal Izquierdo",
     xlab = "Tiempo (segundos)", ylab = "Amplitud")


plot(tiempo, audio@right, type = "l",
     main = "Canal Derecho",
     xlab = "Tiempo (segundos)", ylab = "")

par(mfrow = c(1, 1))
```

El parámetro fundamental en este estudio es la energía, definida como la amplitud al cuadrado de la señal. En la siguiente figura se representa la energía de la señal, donde se observa que ambos canales presentan picos pronunciados. Esta concentración de energía indica una baja entropía, mientras que una distribución de energía uniforme dificultaría la compresión. Una señal con picos de energía concentrado permite un umbralado más eficiente en el dominio wavelet.


La compresión de una señal mediante umbralizado de energía en el dominio wavelet busca concentrar la energía de la señal en un número reducido de coeficientes, eliminando aquellos que aportan poca contribución energética. Este proceso modifica la distribución estadística de la energía, haciendo que esta se concentre en menos estados. Como consecuencia la señal resultante presenta una distribución menos uniforme, lo que conlleva a una reducción de la entropía.

Para analizar de forma cuantitativa este efecto, se estudia la entropía de Shannon asociada a la distribución de energía de los coeficientes wavelet tras haber umbralizado. La entropía se calcula a partir del histograma de energías, en el que cada bin representa un simbolo discreto. De esta forma se puede medir de manera robusta el grado de concentración energética dado por el parámetro umbral $\lambda$. Con el fin de normalizar la magnitud se introduce el concepto de redundancia definida como:

$$R(\lambda)=1-\frac{H(\lambda)}{H_{max}}$$

Donde $H(\lambda)$ es la entropía de la distribución de energía de los coeficientes wavelet tras umbralizar y $H_{max}=\log_2(N_{bins})$ con $N_{bins}$ el número de bins que se mantiene constante para todos los valores de $\lambda$. Una redundancia elevada indica que la entropía de la señal está concentrada en un número reducido de estados, lo que indica que la señal presenta una alta compresibilidad. 

Se ha seleccionado el formato `.rds` para el análisis del almacenamiento debido a su capacidad para preservar la estructura de los coeficientes wavelet, incluyendo los valores nulos generados por el umbralado. A diferencia del formato `.wav`, que almacena la señal reconstruida en el dominio temporal sin tener en cuenta la presencia de ceros. 
El porcentaje de archivo comprimido se calcula como el tamaño relativo del archivo `.rds` normalizado respecto al tamaño máximo obtenido para $\lambda=0$, correspondiene al caso sin compresión. De esta manera, esta magnitud refleja la reducción de información estructural debida al umbralado.


# Resultados

```{r}
crear_tabla_errores <- function(imagen_orig, imagen_comprimida, ruta_orig, ruta_comprimida, titulo){
  mse <- MSE(imagen_orig, imagen_comprimida)
  psnr <- PSNR(imagen_orig, imagen_comprimida)
  ssim <- SSIM(imagen_orig, imagen_comprimida)
  cr <- CR(ruta_orig, ruta_comprimida)

  knitr::kable(data.frame(mse, psnr, ssim, cr), 
        caption = titulo,
        align = "c",
        col.names = c('MSE', 'PSNR', 'SSIM', 'CR'),
        digits = 4,
        escape = FALSE)
}
```

```{r}
crear_tabla_errores(acantilado, acantilado_IDWT, ruta_acantilado, "data_comp/acantilado_IDWT.jpg", "Compresión acantilado IDWT")
```


```{r}
crear_tabla_errores(acantilado, acantilado_DCT, ruta_acantilado, "data_comp/acantilado_DCT.jpg", "Compresión acantilado DCT")

```
```{r}
crear_tabla_errores(flores, flores_IDWT, ruta_flores, "data_comp/flores_IDWT.jpg", "Compresión flores IDWT")
```


```{r}
crear_tabla_errores(flores, flores_DCT, ruta_flores, "data_comp/flores_DCT.jpg", "Compresión flores DCT")
```

```{r}
crear_tabla_errores(noche, noche_IDWT, ruta_noche, "data_comp/noche_IDWT.jpg", "Compresión noche IDWT")
```


```{r}
crear_tabla_errores(noche, noche_DCT, ruta_noche, "data_comp/noche_DCT.jpg", "Compresión noche DCT")
```

```{r}
crear_tabla_errores(dibujo, dibujo_IDWT, ruta_dibujo, "data_comp/dibujo_IDWT.jpg", "Compresión dibujo IDWT")
```


```{r}
crear_tabla_errores(dibujo, dibujo_DCT, ruta_dibujo, "data_comp/dibujo_DCT.jpg", "Compresión dibujo DCT")
```



## Compresión de vídeo

### Compresión imagen

### Compresión del audio

Para buscar el mejor valor umbral se va a buscar aquel valor que tiene una alta reducción del archivo maximizando el valor de la redundancia sin eliminar información relevante. En la siguiente figura se representa el porcentaje de archivo comprimido frente a la redundancia de la señal wavelet.

```{r,fig.width=6, fig.height=4}
lambda_vals <- seq(0, 1, by = 0.1)
lambda_vals_2<-seq(0, 0.3, by = 0.1)
red_data <- redundancy_vs_lambda(
  audio,
  n.levels,
  lambda_vals = lambda_vals
)

size_data <- size_vs_lambda(
  audio     = audio,
  n.levels  = n.levels,
  lambda_vals = lambda_vals
)

plot(
  red_data$redundancy,
  size_data$size_bytes/max(size_data$size_bytes),
  type = "b", pch = 19,
  col = "darkred",
  xlab = "Redundancia",
  ylab = "Porcentaje de archivo comprimido",
  main = "Porcentaje de archivo comprimido vs redundancia"
)
text(
  red_data$redundancy[1:3],
  (size_data$size_bytes / max(size_data$size_bytes))[1:3],
  labels = paste0(expression(lambda =), lambda_vals[1:3]),
  pos = 4,
  cex = 0.75
)
grid()

```

Se observa que el valor óptimo, que logra un equilibrio entre una alta redundancia y la preservación de la información de la señal, corresponde a un umbral de $\lambda=0.1$. Por tanto, este será el valor utilizado para la compresión definitiva del audio.


```{r}
# Parámetros
lambda <- 0.1

# DWT + threshold
vals <- dwt_values(audio, n.levels, lambda)

q_left  <- vals$thr_left
q_right <- vals$thr_right

# Codificación
enc_left  <- encode_wt(q_left)
enc_right <- encode_wt(q_right)

# Guardar archivo comprimido
size_bytes <- save_compressed(
  "data_comp/audio_wavelet_comp.rds",
  left  = enc_left,
  right = enc_right,
  filter = "la8",
  n.levels = n.levels
)

#cat("Tamaño del archivo comprimido:", size_bytes/1024, "KB\n")

```

El mapa de calor de los coeficientes de detalle permite visualizar la distribución de la energía de la señal a través de las seis escalas wavelet. Las áreas en rojo representan coeficientes con valores cercanos a cero, mientras que las zonas amarillas y blancas indican la presencia de componentes de alta energía. Tras aplicar el umbral se observa una escasez estructural, especialmente en los niveles más finos $d_1$ y $d_2$. En la siguiente figura se ha representado únicamente el canal izquierdo por simplicidad, pero sería análogo con el canal derecho.

```{r,dev="png", dpi=300, fig.width=10, fig.height=4}
par(mfrow = c(1, 2))
plot_heatmap_wavelet_coef(audio,n.levels,lambda,threshold=F)
plot_heatmap_wavelet_coef(audio,n.levels,lambda,threshold=T)
par(mfrow = c(1, 1))
```

Se ha aplicado una función de expansión para compensar el submuestreo intrínseco de la DWT, donde los niveles más profundos como $d_6$ contienen menos coeficientes que los niveles finos. Permite alinear todas las escalas con la longitud original de la señal, facilitando una comparación visual directa de la energía en cada instante de tiempo.

```{r,fig.width=6, fig.height=4}
plot_energy_vs_coeff(audio,n.levels,lambda)
```

En la representación de la energía capturada frente a coeficientes se observa que una fracción mínima de los coeficientes logra capturar el $90\%$ de la energía total del audio, en torno a los 25000 primeros coeficientes. Esto permite eliminar la gran mayoría de los coeficientes con menor energía sin generar una pérdida de información significativa.



```{r}

wt_left_rec <- decode_wt(enc_left, vals$thr_left)

wt_right_rec <- decode_wt(enc_right, vals$thr_right)

# Señal final
signal_left_rec  <- wavelets::idwt(wt_left_rec)
signal_right_rec <- wavelets::idwt(wt_right_rec)

audio_wav <- Wave(
    left = signal_left_rec,
    right = signal_right_rec,
    samp.rate = audio@samp.rate,
    bit = audio@bit
)
writeWave(audio_wav, "data_comp/audio2comp.wav")


mse_left  <- sqrt(mean((audio@left - signal_left_rec)^2)) /sqrt(mean(audio@left^2))
mse_right <- sqrt(mean((audio@right - signal_right_rec)^2))/sqrt(mean(audio@right^2))


```

Para ver el efecto de la señal comprimida se va a comprar la amplitud de la señal original (rojo) y la señal comprimida (negro). A pesar de haber eliminado solo un $10\%$ de la energía hay un efecto importante en la señal como se puede ver en la figura.

```{r,dev="png", dpi=300, fig.width=10, fig.height=4}
audio_comp <- readWave("data_comp/audio2comp.wav")


N <- length(audio_comp@left)
freq <- audio_comp@samp.rate

tiempo <- (0:(N-1)) / freq


par(mfrow = c(1, 2), mar = c(4, 4, 2, 1)) 


plot(tiempo,audio@left,type="l",col="red",main = "Canal Izquierdo",xlab = "Tiempo (segundos)", ylab = "Amplitud")
lines(tiempo, audio_comp@left, type = "l", col = "black")


plot(tiempo,audio@right,type="l",col="red",main = "Canal Derecho",xlab = "Tiempo (segundos)", ylab = "")
lines(tiempo, audio_comp@right, type = "l", col = "black")

par(mfrow = c(1, 1))
```

Para el valor de $\lambda=0.1$ el error cuadrático medio normalizado tras comprimir en el canal izquierdo es `r round(mse_left,2)` y para el canal derecho `r round(mse_right, 2)`. Esto indica una pérdida apreciable pero concentrada en coeficientes de baja energía, manteniendo una estructura perceptualmente reconocible de la señal.



```{r}
# Comprimimos los frames del video con cada algoritmo
# frames_orig <- list.files(path = "data/frames", full.names = TRUE, recursive = FALSE)
# 
# for (frame in frames_orig){
#   compresion_DCT_opt(frame, "data_comp/frames_comp")
# }
```


```{r}
# Juntar imagen y video comprimido (funciones_audio.R)
rebuild_video_comp()
```



# Conclusiones

# Link del repositorio
https://github.com/JuanAlcarazAED/Trabajo_AS.git

# Referencias

