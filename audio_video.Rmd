---
title: "Compresión del audio"
author: "Javier Herrero Pérez"
date: "2025-12-04"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Compresión del audio

## Separar audio y video

```{r}
# Librerías
library(av)

library(wavelets)
library(tuneR)

library(RColorBrewer)
```





```{r}
# Página que voy a usar de referencia
#https://stackoverflow.com/questions/36756500/visualization-of-wavelets-coefficients-for-different-deconstruction-levels 
# Apuntes del tema 3 de compresión de una onda

# Funciones importantes

sep_audio_video<-function(main="data/video.mp4",audio="data/audio.wav",video="data/frames",fps=30){
  # Función para separar imagen de audio
  av_audio_convert(main,audio)
  frames<-av_video_images(main,destdir=video,fps=fps)
}


expand_to_length <- function(coefs, target_len) {
rep_each <- ceiling(target_len / length(coefs))
expanded <- rep(coefs, each = rep_each)
expanded[1:target_len]
}
hard_threshold <- function(coefs, lambda) {
  power<-abs(coefs)**2
  coefs[abs(coefs) <= lambda * max(abs(coefs))] <- 0
  return(coefs)
}

plot_heatmap_wavelet_coef<-function(audio,n.levels,lambda,plot="left",threshold=F){
  vals<-dwt_values(audio,n.levels,lambda)
  if (threshold==F){
    if (plot=="left"){
      wt<-vals[[1]]
    }
    else{
      wt<-vals[[2]]
    }
  }
  else{
    if (plot=="left"){
      wt<-vals[[3]]
    }
    else{
      wt<-vals[[4]]
    }
    
  }
  L<- length(audio@left)
  
  coef_list <- lapply(1:n.levels, function(i) {
    expanded <- expand_to_length(wt@W[[i]], L)
    log1p(abs(expanded)^2)
  })
  coef_matrix_raw <- do.call(cbind, coef_list)
  coef_matrix <- (coef_matrix_raw[, 1:n.levels])
  
  colores <- brewer.pal(9, "YlOrBr")
  
  image(x=1:L,y=1:n.levels,z=(coef_matrix),main="Wavelet coeficientes de detalle heatmap",xlab="Tiempo",ylab="Nivel wavelet",yaxt="n")
  axis(side=2,at=1:n.levels,labels = paste0("d", 1:n.levels))
}


plot_umbralD<-function(audio,n.levels,lambda,i,plot="left",threshold=F){
  # Coeficientes del nivel i
  vals<-dwt_values(audio,n.levels,lambda)
    if (threshold==F){
    if (plot=="left"){
      wt<-vals[[1]]
    }
    else{
      wt<-vals[[2]]
    }
  }
  else{
    if (plot=="left"){
      wt<-vals[[3]]
    }
    else{
      wt<-vals[[4]]
    }
    
  }
  coefs <- wt@W[[i]]
  
  # Energía logarítmica (solo la calculamos una vez)
  power <- log(1+abs(coefs)^2)
  
  # Umbral relativo
  umbral <- lambda * max(power)
  
  # Índices que superan el umbral
  idx_keep <- which(power >= umbral)
  
  # Límite vertical para el plot
  y_lim <- 1.1 * max(abs(coefs))
  
  # Grafica
  plot(
    coefs, type = 'l',
    main = paste("Nivel de Detalle d", i),
    xlab = "Índice del Coeficiente",
    ylab = bquote(w[.(i)]),
    ylim = c(-y_lim, y_lim),
    col = "darkgray"
  )
  
  # Añadimos puntos thresholded
  points(
    x = idx_keep,
    y = coefs[idx_keep],
    col = "blue",
    pch = 19,
    cex = 0.6
  )
}

plot_energy_vs_coeff<-function(audio,n.levels,lambda,plot="left"){
    vals<-dwt_values(audio,n.levels,lambda)
    if (plot=="left"){
      wt<-vals[[1]]
      wt_thresholded<-vals[[3]]
    }
    else{
      wt<-vals[[2]]
      wt_thresholded<-vals[[4]]
    }

    
  
  all_coefs <- unlist(wt@W)
  energies <- abs(all_coefs)^2
  # Ordenar por energía descendente
  ord <- order(energies, decreasing = TRUE)
  coefs_sorted <- all_coefs[ord]
  energies_sorted <- energies[ord]
  # Energía total
  E_total <- sum(energies_sorted)
  
  E_cum <- cumsum(energies_sorted)
  
  # Porcentaje de energía
  percent_energy <- E_cum / E_total * 100
  
  # Número de coeficientes preservados
  k_vals <- 1:length(all_coefs)
  
  plot(k_vals, percent_energy,
       type = "l",
       col = "darkorange",
       lwd = 2,
       xlab = "Número de coeficientes preservados",
       ylab = "Energía capturada (%)",
       main = "Curva energía capturada vs coeficientes preservados")
  coefs_keep <- sum(unlist(lapply(wt_thresholded@W, function(v) v != 0)))
  
  # Porcentaje correspondiente
  energy_keep <- percent_energy[coefs_keep]
  
  points(coefs_keep, energy_keep, pch = 19, col = "blue", cex = 1.3)
  text(coefs_keep, energy_keep, labels = " umbral", pos = 4)
  grid()
  }

dwt_values<-function(audio,n.levels,lambda){
  signal_left<-as.numeric(audio@left)
  signal_rigth<-as.numeric(audio@right)
  L <- length(signal_left)
  wt_left <- dwt(signal_left, filter = "la8", n.levels = n.levels)
  wt_right <- dwt(signal_rigth, filter = "la8", n.levels = n.levels)
  wt_thresholded_left <- wt_left 
  wt_thresholded_right <- wt_right 
  wt_thresholded_left@W <- lapply(wt_left@W, function(W_i) {hard_threshold(W_i, lambda)})
  wt_thresholded_right@W <- lapply(wt_right@W, function(W_i) {hard_threshold(W_i, lambda)})
  return(list(
    wt_left  = wt_left,
    wt_right = wt_right,
    thresholded_left  = wt_thresholded_left,
    thresholded_right = wt_thresholded_right
  ))
}


entropy <- function(x) {
  p <- table(x) / length(x)
  -sum(p * log2(p))
}



audio_compress<-function(audio,n.levels,lambda,ruta="data_comp/audio_comp2.wav"){
  vals<-dwt_values(audio,n.levels,lambda)
  
  wt_left  <- vals[[1]]
  wt_right <- vals[[2]]
  thresholded_left  <- vals[[3]]
  thresholded_right <- vals[[4]]
  
  
  # signal_compressed_left <- idwt(thresholded_left)
  # signal_compressed_right <- idwt(thresholded_right)
  signal_compressed_left <- idwt(wt_left)
  signal_compressed_right <- idwt(wt_right)
  
  # Juntar el audio comprimido
  compressed_audio <- Wave(left = signal_compressed_left,
                           right=signal_compressed_right,
                           samp.rate = audio@samp.rate,
                           bit = audio@bit)
  writeWave(compressed_audio, ruta)
}


reconstruir_video <- function(frames_dir = "data/frames",
                              audio_comp = "data_comp/audio_comp.wav",
                              output = "data_comp/video_final.mp4",
                              fps = 30) {
  
  # Creamos un patrón para leer los frames (images)
  frames <- list.files(frames_dir, full.names = TRUE)
  
  # Asegurarnos de que se ordenan en orden numérico
  frames <- frames[order(nchar(frames), frames)]
  
  # Codificar el video a partir de las imágenes y el audio comprimido
  av::av_encode_video(
    input = frames,
    output = output,
    framerate = fps,
    audio = audio_comp
  )
  
}

```


```{r}
audio_compress(audio,n.levels,lambda)
```




```{r}
reconstruir_video()
```






## Análisis 
Separar audio de imagen:
```{r}
sep_audio_video()
```

Parámetros:
```{r}
lambda <- 0.99
n.levels <- 2
audio <- readWave("data/audio.wav")
```


```{r}
plot_heatmap_wavelet_coef(audio,n.levels,lambda,threshold=F)
plot_heatmap_wavelet_coef(audio,n.levels,lambda,threshold=T)


for (i in 1:n.levels){
  plot_umbralD(audio,n.levels,lambda,i,plot="left",threshold=F)
}

plot_energy_vs_coeff(audio,n.levels,lambda)
```



Los puntos azules son los que sobreviven a la compresión, todo lo gris se elimina



## Comprimir el audio 


```{r}
audio_compress(audio,n.levels,lambda)
```





```{r}
total_coefs <- 0
zero_coefs <- 0

# W contiene los coeficientes de detalle
for (W_i in wt_thresholded@W) {
    total_coefs <- total_coefs + length(W_i)
    zero_coefs <- zero_coefs + sum(W_i == 0)
}

V_final <- wt_thresholded@V[[n.levels]]
total_coefs <- total_coefs + length(V_final)
zero_coefs <- zero_coefs + sum(V_final == 0)

sparsity_ratio <- zero_coefs / total_coefs
```

```{r}
bits_original <- audio@bit
H <- entropy(round(wt_thresholded@W$W1))
redundancy <- (bits_original - H) / bits_original
redundancy
```

```{r}
compress_audio_wavelet_to_aac <- function(audio,
                                          n.levels,
                                          lambda,
                                          ruta_aac = "data_comp/audio_comp.aac",
                                          ruta_wav_tmp = "data_comp/tmp_audio.wav") {
  # 1. Obtener coeficientes wavelet y los umbralizados
  vals <- dwt_values(audio, n.levels, lambda)
  
  wt_left  <- vals[[1]]
  wt_right <- vals[[2]]
  thr_left <- vals[[3]]
  thr_right <- vals[[4]]
  
  # 2. Reconstruir señal comprimida
  signal_left  <- idwt(thr_left)
  signal_right <- idwt(thr_right)

  # signal_left  <- idwt(wt_left)
  # signal_right <- idwt(wt_right)
  # 3. Crear objeto Wave
  print(max(abs(signal_left)))
  
  audio_wav <- Wave(left = signal_left,
                    right = signal_right,
                    samp.rate = audio@samp.rate,
                    bit = audio@bit)

  # audio_wav<-Wave(left = rep(0.0, length(signal_left)),
  #                     right = rep(0.0, length(signal_right)),
  #                     samp.rate = audio@samp.rate,
  #                     bit = audio@bit)
  
  # 4. Guardar WAV temporal (PCM sin comprimir)
  writeWave(audio_wav, ruta_wav_tmp)
  
  # 5. Convertir a AAC (códec comprimido real)
  av::av_audio_convert(ruta_wav_tmp, ruta_aac)
  
  
  
}

compress_audio_wavelet_to_aac(
  audio = audio,
  n.levels = 6,
  lambda = 0,
  ruta_aac = "data_comp/audio_comp.aac"
)
```




